---
title: "Recitation 15: Ensemble Learning"
author: "Seamus Wagner"
date: "`r Sys.Date()`"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5, fig.align = "center", echo=T, warning=FALSE, message=FALSE)
```


```{r}
rm(list=ls())
library(SuperLearner)
library(kernlab)
library(data.table)
library(ROCR)
set.seed(877654)
load("C:/Users/spw51/Downloads/c2c-A21 (1).Rdata")

# useful for which models you can use. Some require extra packages to work (kernlab, arm, etc)
# ksvm is kernel support vector machine, which is why I have kernlan loaded. I don't end up using it 
listWrappers()
```

```{r}
Y <- data$responder # SuperLearner wants a separate X and Y as input
X <- data[, -c("Y", "responder")]
?SuperLearner
sl <- SuperLearner(
Y, X, newX = X, family = binomial(), #binomial as we want a logit in this case since our outcome is response [0,1]
SL.library = "SL.glm", #the type of model to use
method = "method.AUC", #the type of method to evaluate the model
verbose = FALSE, 
cvControl = SuperLearner.CV.control( #cvcontrol is for control in cross valdiation, v is number of folds, stratifycv is for whether they should be stratified in a binary sense, false is deafult. Shuffle is whether rows should be shuffled as splits are made, default is true. ValidRows is only if you pre-shuffle and can provide a list of rows for each split. These are default values. ValidRows is useful in some practical settings if you want to create your lists and use the same ones across packages or tests. 
V = 10L,
stratifyCV = FALSE,
shuffle = TRUE,
validRows = NULL))
?SuperLearner
hist(sl$SL.predict)
```

```{r}
calc_AUROC <-
  function(predictions, labels) {
    performance(prediction(predictions, labels), measure = "auc")@y.values[[1]]
  } 
calc_AUROC(sl$SL.predict[, 1], data[, responder])
```

```{r}
mean(sapply(1:10, function(i) {
  test_rows <- sl$validRows[[i]] # here's where the test set rows live
  calc_AUROC(sl$SL.predict[test_rows, 1], data[test_rows, responder])
}))
```
```{r}
# Inverse probability weights are 1 over predicted values, that way you get a weight for each value

# After that, you can apply those weights to your Y := formula for all responders.

# That will give you a weighted mean estimate to compare to the naive one. 
```


