---
title: "Recitation 3 Randomization"
author: "Seamus Wagner"
date: "September 14, 2021"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=8, fig.height=5, fig.align = "center", echo=FALSE, warning=FALSE, message=FALSE)
```

```{r, echo = F}
library(dplyr)
library(data.table)
library(stargazer)
library(gridExtra)
library(ggplot2)
library(fixest)
library(margins)
library(foreign)
setwd("E:/Quant 3 TA/Recitations/Scripts/Recitation 3")
```

Since we have an extra week for this problem set, I will set up the labs in two parts. The first part is mostly dealing with data manipulation and visualization and the second part with randomization. Wednesday and Friday will cover randomization in depth and William is obviously better suited to introduce that information than I. Next Tuesday we will revisit it with some examples in lab. 

Today, I will walk you through how to approach a dataset you are interested in working with and exploring what it holds. For today, we will be using Afrobarometer's Round 7 data. Afrobarometer is a public attitudes survey conducted across Sub-Saharan Africa every few years. I have quite a bit of experience with Afrobarometer data, though I have not used round 7 yet. The first step is to find out what format the data are stored in and find a way to easily access and read the data contained. Once you do that, it can be a good idea to write the data into a more universal file format. Some people save as .txt, though I prefer .csv. 

These data are in .sav and unless you have SPSS on your computer or want to make a trip to the lab just to see the data, I recommend using the foreign package in R to read SPSS files and then save them in a better format. The two commands after the file name are useful for reading data. The use.value.labels turns those labels into factors, which is helpful for things like regions and countries but I prefer to have them as FALSE since it keeps. The to.data.frame prevents the reading as coming from a list and then needing to further manipulate it into a more readily-accessible object. Note, reading this way can take some time, even with relatively small, about 50k datasets. 


```{r}
rm(list=ls())
ab7 <- read.spss("r7_merged_data_34ctry.release.sav", use.value.labels = F, to.data.frame = T)
#?read.spss
```

Once we have the data, it is a good idea to check out what the structure is and what the data look like. This is also a good time to keep the codebook (assuming one accompanies the dataset, which is not always true) handy and look through the variables of interest to you. Further, make sure to keep an eye for alternative variables and potential robustness checks that someone may ask you to run to strengthen your argument. I am about to limit the data severely for time purposes, but it is typically not a good idea to do this, you want to keep as much data as possible. 

```{r}
#Checking the structure, for larger datasets, the list.len for str or summary is
#helpful. Here we only display the first 20 variables.
#str(ab7, list.len = 5) 
#summary(ab7, list.len = 5)
#Turning it into a data table
afro_subset <- data.table(ab7)
#Here is where we have the decision of looking through the dataset first to 
#determine what variables we want or to move along with full data and explore.

#The order of the name changing and the concatination of variables for 
#subsetting matters for practical purposes. It makes the most sense to rename 
#the variables into what you intend to use them for and then storing them as a 
#list, otherwise you would have to repeat the myvars <- ()step
setnames(afro_subset,"RESPNO", "id")
setnames(afro_subset,"COUNTRY", "country")
setnames(afro_subset,"URBRUR", "urbrur")
setnames(afro_subset,"REGION", "region")
setnames(afro_subset,"Q1", "age")
setnames(afro_subset,"Q2A", "language")
setnames(afro_subset,"Q98", "religion")
setnames(afro_subset,"Q97", "education")
setnames(afro_subset,"Q88B", "party_id")
#Some surveys like AB ask multiple questions that you could use for party id
#For instance, the wording of Q88B refers to Q88, which asks if someone feels 
#a close conneciton to a particular party in essence whereas Q99 asks if 
#elections were held tomorrow, which party would you support?
setnames(afro_subset,"Q99", "party_election_pref")
setnames(afro_subset,"Q84", "ethnic_id")
setnames(afro_subset,"Q85B", "nat_eth_id")
setnames(afro_subset,"Q3", "current_direction")
setnames(afro_subset,"Q4B", "personal_econ_cond")

myvars <- c("id", "country", "urbrur", "region", "age", "language", "religion",
            "education", "party_id", "party_election_pref", "ethnic_id", 
            "nat_eth_id", "current_direction", "personal_econ_cond")
afro_subset <- afro_subset[ , ..myvars]
```

Now that we have a limited number of variables we may be interested in, we should check their codings.

```{r}
rm(ab7)
#str(afro_subset)
#summary(afro_subset)
```
Next, we will create some visualizations of the data and see what our distributions are. For this, I think using ggarange or multiplot are useful tools. That way, we can create plots in bulk and visualize about 6 at a time. 

```{r, include=T}
#Check the variable names for easy copying without human error
names(afro_subset)

#Check each varaible to make sure the codes make sense
table(afro_subset$urbrur)

#Here we see that peri-urban (430) is not useful for visualization, so we 
#should recode it as factor in the plot.

fig1 <- ggplot(afro_subset) +
  geom_bar(aes(x = as.factor(urbrur)), fill = "black") +
  xlab("Urban Rural residence") +
  ylab("Count") + 
  ggtitle("Urban and Rural residence") +
  scale_x_discrete(labels = c('Urban','Rural','Semi-Urban', 'Peri-Urban')) +
  theme_bw() 
```

```{r}
table(afro_subset$age)
#Here we see 998 and 999, which are coded as missing or refusals, so we should 
#remove them unless we are taking an imputation approach.
#The ifelse here means if age = 998 OR 999, make it NA, otherwise keep values
afro_subset$age <- ifelse(afro_subset$age == 998 | afro_subset$age == 999|
                          afro_subset$age ==  -1,NA, afro_subset$age)

fig2 <- ggplot(afro_subset) +
  geom_histogram(aes(x = age), fill = "black", binwidth = 1) +
  xlab("Age") +
  ylab("Count") + 
  ggtitle("Age of respondents") +
  theme_bw()
```

```{r}
table(afro_subset$language)
afro_subset$language <- ifelse(afro_subset$language == 9995 | 
                                 afro_subset$language == 9998 | 
                                 afro_subset$language == 9999|
                                 afro_subset$language == -1, NA, afro_subset$language)
#This one is not as useful for visualization as there are too many categories 
#for discrete visualization and ordered numeric doesn't make sense for 
#categorical data

#Same for religion and ethnicity coming up
```

```{r}
table(afro_subset$religion)
afro_subset$religion <- ifelse(afro_subset$religion == 9995 | 
                                 afro_subset$religion == 9998 |
                                 afro_subset$religion == 9999 |
                                 afro_subset$religion == -1, NA, afro_subset$religion)

```

```{r}
table(afro_subset$ethnic_id)
afro_subset$ethnic_id <- ifelse(afro_subset$ethnic_id == 9990 |
                                  afro_subset$ethnic_id == 9995 | 
                                  afro_subset$ethnic_id == 9996 |
                                 afro_subset$ethnic_id == 9998 |
                                 afro_subset$ethnic_id == 9999, NA, afro_subset$ethnic_id)

```

```{r}
table(afro_subset$education)
afro_subset$education <- ifelse(afro_subset$education == 98 | 
                                  afro_subset$education == 99 | 
                                  afro_subset$education == -1, NA, afro_subset$education)
fig3 <- ggplot(afro_subset) +
  geom_bar(aes( x = as.factor(education)), fill = "Black") +
  xlab("Education type/level") +
  ylab("Count") + 
  ggtitle("Education Level") +
  theme_bw() +
  scale_x_discrete(labels = c('None','Informal','Some primary', 'Primary', "Some secondary", "secondary", "Post-secondary",
                              "Some Uni", "University", 
                              "Post-graduate")) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1))

```

```{r}
table(afro_subset$party_id)
afro_subset$party_id <- ifelse(afro_subset$party_id == 9995 |
                                 afro_subset$party_id == 9996 |
                                 afro_subset$party_id == 9997 |
                                 afro_subset$party_id == 9998 |
                                 afro_subset$party_id == 9999 |
                                 afro_subset$party_id == -1,NA,afro_subset$party_id)
```

```{r}
table(afro_subset$party_election_pref)
afro_subset$party_election_pref <- ifelse(afro_subset$party_election_pref == 9995 |
                                 afro_subset$party_election_pref == 9996 |
                                 afro_subset$party_election_pref == 9997 |
                                 afro_subset$party_election_pref == 9998 |
                                 afro_subset$party_election_pref == 9999 |
                                 afro_subset$party_election_pref == -1,NA,afro_subset$party_election_pref)

```

```{r}
table(afro_subset$nat_eth_id)
afro_subset$nat_eth_id <- ifelse(afro_subset$nat_eth_id == 99 |
                                   afro_subset$nat_eth_id == 7 |
                                   afro_subset$nat_eth_id == 8 |
                                   afro_subset$nat_eth_id == 9 |
                                   afro_subset$nat_eth_id == -1, NA, afro_subset$nat_eth_id)

fig4 <- ggplot(afro_subset) +
  geom_bar(aes(x = as.factor(nat_eth_id)), fill = "Black") +
  xlab("Identity") +
  ylab("Count") + 
  ggtitle("National versus Ethnic Identity") +
  theme_bw() +
  scale_x_discrete(labels = c('Ethnic only','More ethnic','Equal', 'More national', "National only")) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1))

```

```{r}
table(afro_subset$current_direction)
afro_subset$current_direction <- ifelse(afro_subset$current_direction == -1 |
                                          afro_subset$current_direction == 8 | 
                                          afro_subset$current_direction == 9, 
                                        NA, afro_subset$current_direction)

afro_subset$current_direction <- ifelse(afro_subset$current_direction == 1,0,1)
fig5 <- ggplot(afro_subset) +
  geom_bar(aes(x = current_direction), fill = "Black") +
   xlab("Current Economic Conditions") +
  ylab("Count") + 
  ggtitle("National economic condition") +
  theme_bw()
```

```{r}
table(afro_subset$personal_econ_cond)
afro_subset$personal_econ_cond <- ifelse(afro_subset$personal_econ_cond == -1 |
                                          afro_subset$personal_econ_cond == 8 | 
                                          afro_subset$personal_econ_cond == 9, 
                                        NA, afro_subset$personal_econ_cond)
fig6 <- ggplot(afro_subset) +
  geom_bar(aes(x = personal_econ_cond), fill = "Black") +
   xlab("Personal Economic Conditions") +
  ylab("Count") + 
  ggtitle("Personal economic conditions") +
  theme_bw()
```

Now that we have the data cleaned and plots made, we can take a look at them. The step above takes a decent bit of time, particularly with new datasets and formats you are unfamiliar with. Finding a codebook is useful, but keep in mind that codebooks for panel or temporal data may shift over time. Take note of reverse codings as well, where two questions next to each other may be coded in opposite directions as you suspect. Finally, codebooks and datasets have errors, use intuition at times when you are unsure, also ask other people that use them. 

```{r}
grid.arrange(fig1, fig2, fig3, fig4, fig5, fig6, ncol=2)
```

A few things stand out to check. First, Most respondents are urban or rural. One way to deal with this to make a binary would be to select either urban or rural, and make those values a 1 and make all otters a 0. This lets you keep the data if you operate under the assumption that whichever category is a 1 is distinct enough from the others to make a theoretical difference. If you cannot make that assumption, do not combine them. Moreover, age has some interesting trends that are likely non-random. We can explore that further later, but it seems like certain values are showing up at a much higher rate than they should. We would expect that people residing at home during the enumeration time may be systematically different in some way, and good survey companies will give you these data. AB records time of interview, number of times approached, and outlines their rigorous methodology for who is to be selected at each household. In this case, it is likely people reporting the nearest age ending in 0 or 5, though I have not checked. Education is clearly right-skewed and indicates most respondents have not completed the equivalent of high school. For national versus ethnic identity, this is actually a shift into neutrality and national identity that may be driven by social-desirability bias. In previous rounds, this question is strongly right-skewed. Lots of NAs in this question as well, another indication of cautious respondents. We can see in the bottom two figures that few respondents think that economic conditions are excellent for either themselves or their country. Let's say we want to test for the correlation of perceptions of current economic conditions on perceptions of naitonal economic conditions, which is one correlate of voting behvior in the US. 

```{r}
names(afro_subset)


#Factors take a while in base R regression frameworks
afro_subset$language <- as.factor(afro_subset$language)
afro_subset$religion <- as.factor(afro_subset$religion)
afro_subset$education <- as.factor(afro_subset$education)
afro_subset$ethnic_id <- as.factor(afro_subset$ethnic_id)
afro_subset$party_id <- as.factor(afro_subset$party_id)
afro_subset$urbrur <- as.factor(afro_subset$urbrur)

#Creating lists for your IV/DV is helpful when you are running many models and 
#potentially many variations of formula. This way you can plug and play within 
#the model brackets for a new formula, for instance fmla2 could use dv_list[2] 
#instead and then fmla3 could use iv_list[2] but dv_list[1] and so on
#Further, this setup and using the feglm allows for fixed effects (country, 
#survey round, region, colonial power, regime type, you name it.
#The syntax for that would be paste("| country + round | ..."))) after the 
#controls but before the final parentheses. 
dv_list <- c("current_direction")
iv_list <- c("personal_econ_cond", "party_id", "ethnic_id")
controls <- "+education+age+party_id+ethnic_id+urbrur"
fmla1 <- as.formula(paste(paste(dv_list[1],"~"),
                          paste(iv_list[1], "+"),
                          paste(controls)))
#Creating a training set at random for hypothesis testing without using the 
#full set of data
set.seed(4597395)
afro_subset[, train_id := rbinom(nrow(afro_subset),1,.66)]
afro_subset1 <- afro_subset %>%
  filter(train_id == 1)

m1 <- feglm(fmla1, data=afro_subset1,  family = binomial(link = "logit"))
#This is to remove factor levels from the summary and just see the IV
m1$coefficients <- m1$coefficients[1:2]
#This is not best practice but is efficient for testing hypotheses and 
#getting a feel for the data
summary(m1)
```

We see a large substantive effect that is statistically reliable. This is a logit remember, so the coefficient is not super useful by itself. Next steps would e something like marginal effects plots. I am doing a bit more data manipulation for time purposes and clarity. I am coarsening the levels of urban/rural as well as education and only including those two and age as controls. This will allow for a fairly clear marginal effects plot. 

```{r}
test <- afro_subset
afro_subset <- test
afro_subset$education <- as.numeric(afro_subset$education)
afro_subset$urbrur <- ifelse(afro_subset$urbrur == 3 | afro_subset$urbrur == 430|
                          afro_subset$urbrur ==  2,0, 1)
afro_subset$education <- ifelse(afro_subset$education > 6 , 2,
                                ifelse(afro_subset$education < 7 & afro_subset$education > 4 , 1, 
                                ifelse(afro_subset$education < 5, 0, afro_subset$education)))
  
afro_subset$education <- as.factor(afro_subset$education)
controls <- "+education+age+urbrur"
set.seed(478488854)
afro_subset[, train_id := rbinom(nrow(afro_subset),1,.66)]
afro_subset1 <- afro_subset %>%
  filter(train_id == 1)
fmla2 <- as.formula(paste(paste(dv_list[1],"~"),
                          paste(iv_list[1], "+"),
                          paste(controls)))
#Note for the margins package, data.table causes some plotting errors, so feed
#the data as a data.frame into the regression instead
m2 <- glm(fmla2, data = data.frame(afro_subset1), family = "binomial")
mfx2 <- margins(m2)
summary(margins(m2))
plot(mfx2)
?cplot
cplot(m2, x = "personal_econ_cond")
cplot(m2, x = "education")
cplot(m2, x = "age")
cplot(m2, x = "urbrur")

```